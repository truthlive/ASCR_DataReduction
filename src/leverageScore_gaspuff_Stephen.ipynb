{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import scipy\n",
    "from numpy.random import default_rng\n",
    "import scipy.linalg as sla\n",
    "import scipy.linalg.interpolative as sli\n",
    "\n",
    "from frequentDirections import FrequentDirections\n",
    "import time\n",
    "import h5py\n",
    "from rSVDsp import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streaming_ridge_leverage(A, k, t, epsilon, delta, c, rng=default_rng()):\n",
    "    \"\"\"\n",
    "    from http://arxiv.org/abs/1511.07263\n",
    "    A should be n by d\n",
    "    k is the rank of the projection with theoretical guarantees.\n",
    "    t is the stored column size\n",
    "    epsilon: accuracy parameter\n",
    "    delta: (1 - delta) is the success probability\n",
    "    c: oversampling parameter\n",
    "    choose epsilon and delta to be less than one.\n",
    "    \"\"\"\n",
    "    n, d = np.shape(A)\n",
    "    count = 0\n",
    "    C = np.zeros((n, t))  # Stores actual column subset\n",
    "    D = np.zeros((n, t))  # Stores a queue of new columns\n",
    "    frobA = 0\n",
    "\n",
    "    tau_old = np.ones((t))  # Initialize sampling probabilities\n",
    "    tau = tau_old\n",
    "    l = 2  # parameter for FrequentDirections\n",
    "\n",
    "    sketcher = FrequentDirections(n, (l + 1) * k)\n",
    "    for i in range(d):\n",
    "        a = A[:, i].T\n",
    "        sketcher.append(a)\n",
    "        B = sketcher.get().T\n",
    "        # print(np.shape(B))\n",
    "        if count < t:\n",
    "            D[:, count] = A[:, i]\n",
    "            frobA = frobA + sla.norm(a) ** 2\n",
    "            count = count + 1\n",
    "        else:\n",
    "            tau = np.minimum(tau_old, ApproximateRidgeScores(B, C, frobA, k))\n",
    "            tau_D = ApproximateRidgeScores(B, D, frobA, k)\n",
    "            # print(tau)\n",
    "            # print(tau_D)\n",
    "            for j in range(t):\n",
    "                if not np.all(C[:, j] == 0):\n",
    "                    prob_rej = 1.0 - tau[j] / tau_old[j]\n",
    "                    roll = rng.random()\n",
    "                    if roll < prob_rej:\n",
    "                        C[:, j] = 0\n",
    "                        tau_old[j] = 1.0\n",
    "                    else:\n",
    "                        tau_old[j] = tau[j]\n",
    "                if np.all(C[:, j] == 0):\n",
    "                    for l in range(t):\n",
    "                        prob = (\n",
    "                            tau_D[l]\n",
    "                            * c\n",
    "                            * (k * np.log(k) + k * np.log(1.0 / delta) / epsilon)\n",
    "                            / t\n",
    "                        )\n",
    "                        roll = rng.random()\n",
    "                        if roll < prob:\n",
    "                            C[:, j] = D[:, l]\n",
    "                            tau_old[j] = tau_D[l]\n",
    "            count = 0\n",
    "\n",
    "    return C\n",
    "\n",
    "\n",
    "def rID_streaming_ridge_leverage_old(A, k, t, epsilon, delta, c, os, rng=default_rng()):\n",
    "    \"\"\"\n",
    "    from http://arxiv.org/abs/1511.07263\n",
    "    A should be n by d\n",
    "    k is the rank of the projection with theoretical guarantees.\n",
    "    t is the stored column size\n",
    "    epsilon: accuracy parameter\n",
    "    delta: (1-delta) is the success probability\n",
    "    c: oversampling parameter\n",
    "    os: oversampling number for random projection\n",
    "    choose epsilon and delta to be less than one.\n",
    "    \"\"\"\n",
    "    n, d = np.shape(A)\n",
    "    ll = k + os\n",
    "    Omg = rng.standard_normal(size=(ll, n))\n",
    "\n",
    "    # t = np.ceil(32. * c * (k*np.log(k)+k*np.log(1./delta)/epsilon)).astype(int)\n",
    "    # print(t)\n",
    "\n",
    "    count = 0\n",
    "    nBlock = 0\n",
    "    C = np.zeros((n, t))  # Stores actual column subset\n",
    "    D = np.zeros((n, t))  # Stores a queue of new columns\n",
    "    frobA = 0\n",
    "\n",
    "    Q = np.zeros((t, d))\n",
    "    C_old = C\n",
    "    OmgA = np.zeros((ll, d))\n",
    "\n",
    "    tau_old = np.ones((t))  # Initialize sampling probabilities\n",
    "    tau = tau_old\n",
    "    l = 2  # parameter for FrequentDirections\n",
    "\n",
    "    sketcher = FrequentDirections(n, (l + 1) * k)\n",
    "    for i in range(d):\n",
    "        a = A[:, i].T\n",
    "        sketcher.append(a)\n",
    "        B = sketcher.get().T\n",
    "        OmgA[:, i] = Omg @ A[:, i]\n",
    "        # print(np.shape(B))\n",
    "        if count < t:\n",
    "            D[:, count] = A[:, i]\n",
    "            frobA = frobA + sla.norm(a) ** 2\n",
    "            count = count + 1\n",
    "        else:\n",
    "            # print(B)\n",
    "            tau = np.minimum(tau_old, ApproximateRidgeScores(B, C, frobA, k))\n",
    "            tau_D = ApproximateRidgeScores(B, D, frobA, k)\n",
    "            # print(tau)\n",
    "            # print(tau_D)\n",
    "            for j in range(t):\n",
    "                if not np.all(C[:, j] == 0):\n",
    "                    prob_rej = 1.0 - tau[j] / tau_old[j]\n",
    "                    roll = rng.random()\n",
    "                    if roll < prob_rej:\n",
    "                        C[:, j] = 0\n",
    "                        tau_old[j] = 1.0\n",
    "                    else:\n",
    "                        tau_old[j] = tau[j]\n",
    "                if np.all(C[:, j] == 0):\n",
    "                    for l in range(t):\n",
    "                        prob = (\n",
    "                            tau_D[l]\n",
    "                            * c\n",
    "                            * (k * np.log(k) + k * np.log(1.0 / delta) / epsilon)\n",
    "                            / t\n",
    "                        )\n",
    "                        roll = rng.random()\n",
    "                        if roll < prob:\n",
    "                            C[:, j] = D[:, l]\n",
    "                            tau_old[j] = tau_D[l]\n",
    "            count = 0\n",
    "\n",
    "    idx = np.argwhere(np.all(C[..., :] == 0, axis=0))\n",
    "    C = np.delete(C, idx, axis=1)\n",
    "\n",
    "    print(np.shape(C))\n",
    "\n",
    "    # Q = sla.lstsq(Omg @ C, OmgA)[0]\n",
    "    Q = sla.lstsq(C, A)[0]\n",
    "    return C, Q\n",
    "\n",
    "\n",
    "def rID_streaming_ridge_leverage3(\n",
    "    A, k, t, epsilon, delta, c, os, list_t=None, rng=default_rng()\n",
    "):\n",
    "    \"\"\"\n",
    "    from http://arxiv.org/abs/1511.07263\n",
    "    A should be n by d\n",
    "    k is the rank of the projection with theoretical guarantees.\n",
    "    t is the stored column size\n",
    "    epsilon: accuracy parameter\n",
    "    delta: (1-delta) is the success probability\n",
    "    c: oversampling parameter\n",
    "    os: oversampling number for random projection\n",
    "    choose epsilon and delta to be less than one.\n",
    "    \"\"\"\n",
    "    n, d = np.shape(A)\n",
    "    ll = k + os\n",
    "    Omg = rng.standard_normal(size=(ll, n))\n",
    "\n",
    "    count = 0\n",
    "    nBlock = 0\n",
    "    C = np.zeros((n, t))  # Stores actual column subset\n",
    "    D = np.zeros((n, t))  # Stores a queue of new columns\n",
    "    IC = -1 * np.ones((t)).astype(int)\n",
    "    ID = np.zeros((t)).astype(int)\n",
    "    frobA = 0\n",
    "\n",
    "    Q = np.zeros((t, d))\n",
    "    C_old = C\n",
    "    OmgA = np.zeros((ll, d))\n",
    "    OmgAOmgAt = np.zeros((ll, ll))\n",
    "\n",
    "    tau_old = np.ones((t))  # Initialize sampling probabilities\n",
    "    tau = np.zeros((t))\n",
    "    probabilities = np.zeros((t))\n",
    "\n",
    "    for i in range(d):\n",
    "        a = A[:, i].T\n",
    "        OmgA[:, i] = Omg @ A[:, i]\n",
    "        OmgAOmgAt = OmgAOmgAt + OmgA[:, i] @ OmgA[:, i].T\n",
    "        # OmgAOmgAt = scipy.linalg.blas.dsyr(1.0,OmgA[:, i].flatten(),  a=OmgAOmgAt, overwrite_a = 1) # not good because only overwrites upper triangular portion, so needs postprocessing\n",
    "        #OmgAOmgAt = scipy.linalg.blas.dger(1.0,OmgA[:, i].flatten(),OmgA[:, i].flatten(), overwrite_x = 0, overwrite_y = 0, a=OmgAOmgAt, overwrite_a = 1) # not good because only overwrites upper triangular portion, so needs postprocessing\n",
    "        if count < t:\n",
    "            D[:, count] = A[:, i]\n",
    "            ID[count] = i\n",
    "            frobA = frobA + sla.norm(a) ** 2\n",
    "            count = count + 1\n",
    "        else:\n",
    "            # tau = np.minimum(tau_old, ApproximateRidgeScores2(OmgA[:,:i], Omg, C, frobA, k))\n",
    "            # tau_D = ApproximateRidgeScores2(OmgA[:,:i], Omg, D, frobA, k)\n",
    "            tau, U, eig = ApproximateRidgeScores4(OmgAOmgAt, Omg, C, frobA, k) # returns eigenvalues/vectors\n",
    "            tau = np.minimum( tau_old, tau )\n",
    "            tau_D = ApproximateRidgeScores4(OmgAOmgAt, Omg, D, frobA, k, U=U, eig=eig)[0]\n",
    "            for j in range(t):\n",
    "                if IC[j] != -1:\n",
    "                    prob_rej = 1.0 - tau[j] / tau_old[j]\n",
    "                    roll = rng.random()\n",
    "                    if roll < prob_rej:\n",
    "                        C[:, j] = 0\n",
    "                        tau_old[j] = 1.0\n",
    "                        IC[j] = -1\n",
    "                    else:\n",
    "                        tau_old[j] = tau[j]\n",
    "\n",
    "            num_sample = np.sum(IC < 0)\n",
    "            # print(f'Sum tauD: {np.sum(tau)}')\n",
    "            # print(f'Sum tauD: {np.sum(tau_D)}')\n",
    "            # print(f'Sum: {np.sum(probabilities)}')\n",
    "            idx_sample = np.random.choice(\n",
    "                ID, num_sample, p=tau_D / np.sum(tau_D), replace=False\n",
    "            )\n",
    "            # print(num_sample)\n",
    "            # print(IC)\n",
    "            # print(ID)\n",
    "            # print(idx_sample)\n",
    "            count_sample = 0\n",
    "            for j in range(t):\n",
    "                if IC[j] < 0:\n",
    "                    IC[j] = idx_sample[count_sample]\n",
    "                    idx_D = np.where(ID == IC[j])[0][0]\n",
    "                    # print(idx_D)\n",
    "                    tau_old[j] = tau_D[idx_D]\n",
    "                    C[:, j] = D[:, idx_D]\n",
    "                    count_sample = count_sample + 1\n",
    "\n",
    "                # if IC[j] == -1:\n",
    "                #     for l in range(t):\n",
    "                #         prob = tau_D[l]*c*(k*np.log(k)+k*np.log(1./delta)/epsilon)/t\n",
    "                #         # prob = tau_D[l]/32.\n",
    "                #         roll = rng.random()\n",
    "                #         if roll < prob:\n",
    "                #             C[:,j] = D[:, l]\n",
    "                #             tau_old[j] = tau_D[l]\n",
    "                #             IC[j] = ID[l]\n",
    "\n",
    "            # Q[:,(nBlock)*t:(nBlock+1)*t] = sla.lstsq(Omg @ C, OmgA[:, (nBlock)*t:(nBlock+1)*t])[0]\n",
    "            # if nBlock == 0:\n",
    "            #     C_old = C\n",
    "            # else:\n",
    "            #     P = sla.lstsq(C, C_old)[0]\n",
    "            #     C_old = C\n",
    "            #     Q[:,:(nBlock)*t] = P @ Q[:,:(nBlock)*t]\n",
    "            count = 0\n",
    "            # nBlock = nBlock + 1\n",
    "\n",
    "    # if nBlock * t < d:\n",
    "    #     Q[:, (nBlock)*t:] = sla.lstsq(Omg @ C, OmgA[:, (nBlock)*t:])[0]\n",
    "    C = np.unique(C, axis=1)\n",
    "    # print(C)\n",
    "\n",
    "    Q = sla.lstsq(Omg @ C, OmgA)[0]\n",
    "\n",
    "\n",
    "    IC = np.unique(IC)\n",
    "\n",
    "    return C, Q, IC\n",
    "\n",
    "\n",
    "def truncateSVD_efficient(A, k):\n",
    "    Q, R = sla.qr(\n",
    "        A.T, mode=\"economic\", pivoting=False, check_finite=False\n",
    "    )  # A.T = QR so R.T Q.T = A\n",
    "    U, s, Vh = sla.svd(R.T)  # a little m x m SVD\n",
    "    Vh = Vh @ Q.T\n",
    "\n",
    "    U_k = U[:, range(k)]\n",
    "    Vh_k = Vh[range(k), :]\n",
    "    s_k = s[range(k)]\n",
    "\n",
    "    return U_k, s_k, Vh_k\n",
    "\n",
    "\n",
    "def ApproximateRidgeScores_old(B, M, frobA, k):\n",
    "    n, t = np.shape(M)\n",
    "    tau = np.zeros((t))\n",
    "\n",
    "    # Uk_B, Sk_B ,Vk_B = truncateSVD_efficient(B, k)\n",
    "    # Bk = Uk_B @ (Sk_B.reshape((-1, 1)) * Vk_B)\n",
    "\n",
    "    # kernel_inv = sla.pinv(B@B.T+ (frobA - sla.norm(Bk, 'fro')**2)/k * np.eye(n) )\n",
    "\n",
    "    U, s, _ = sla.svd(B, full_matrices=False)\n",
    "    eig = s**2\n",
    "\n",
    "    BkF2 = np.sum(eig)\n",
    "    ridge_kernel = U.dot(np.diag(1 / (eig + (frobA - BkF2) / k))).dot(\n",
    "        U.T\n",
    "    )  #! ridge leverage\n",
    "\n",
    "    for i in range(t):\n",
    "        m = M[:, i]\n",
    "        tau[i] = 4.0 * m.T.dot(ridge_kernel).dot(m)\n",
    "\n",
    "    return tau\n",
    "\n",
    "\n",
    "def ApproximateRidgeScores(B, M, frobA, k):\n",
    "    \"\"\"\n",
    "    Use frequent direction sketch to compute ridge leverage scores\n",
    "    \"\"\"\n",
    "\n",
    "    n, t = np.shape(M)\n",
    "    tau = np.zeros((t))\n",
    "\n",
    "    # Uk_B, Sk_B ,Vk_B = truncateSVD_efficient(B, k)\n",
    "    # Bk = Uk_B @ (Sk_B.reshape((-1, 1)) * Vk_B)\n",
    "\n",
    "    # kernel_inv = sla.pinv(B@B.T+ (frobA - sla.norm(Bk, 'fro')**2)/k * np.eye(n) )\n",
    "\n",
    "    U, s, _ = sla.svd(B, full_matrices=False)\n",
    "    UtM = U.T @ M\n",
    "    eig = s**2\n",
    "\n",
    "    BkF2 = np.sum(eig[1:k])\n",
    "    # ridge_kernel = U.dot( np.diag(1/(eig + (frobA - BkF2)/k))).dot(U.T) #! ridge leverage\n",
    "    kernel = np.diag(1 / (eig + (frobA - BkF2) / k))\n",
    "\n",
    "    for i in range(t):\n",
    "        m = UtM[:, i]\n",
    "        tau[i] = 4.0 * m.T.dot(kernel).dot(m)\n",
    "\n",
    "    return tau\n",
    "\n",
    "\n",
    "def ApproximateRidgeScores2(OmgA, Omg, M, frobA, k):\n",
    "    \"\"\"\n",
    "    Use random projected sketch to compute ridge leverage scores\n",
    "    \"\"\"\n",
    "    n, t = np.shape(M)\n",
    "    ll, d = np.shape(OmgA)\n",
    "    tau = np.zeros((t))\n",
    "\n",
    "    if ll >= d:\n",
    "        U, s, _ = sla.svd(OmgA, full_matrices=False)\n",
    "        UtOmgM = U.T @ Omg @ M\n",
    "        eig = s**2\n",
    "    else:\n",
    "        # _, R = sla.qr( OmgA.T, mode='economic', pivoting=False, check_finite=False ) # A.T = QR so R.T Q.T = A\n",
    "        U, eig, _ = sla.svd(OmgA @ OmgA.T, full_matrices=False)  # a little m x m SVD\n",
    "        UtOmgM = U.T @ Omg @ M\n",
    "\n",
    "    BkF2 = np.sum(eig[1:k])\n",
    "    kernel = np.diag(1 / (eig + (frobA - BkF2) / k))\n",
    "\n",
    "    for i in range(t):\n",
    "        m = UtOmgM[:, i]\n",
    "        tau[i] = 4.0 * m.T.dot(kernel).dot(m)\n",
    "\n",
    "    return tau\n",
    "\n",
    "\n",
    "def ApproximateRidgeScores3(OmgAOmgAT, Omg, M, frobA, k):\n",
    "    \"\"\"\n",
    "    Use random projected sketch to compute ridge leverage scores, better implementation to handle larger time steps\n",
    "    \"\"\"\n",
    "    _, t = np.shape(M)\n",
    "    tau = np.zeros((t))\n",
    "\n",
    "    U, eig, _ = sla.svd(OmgAOmgAT, full_matrices=False)  # a little m x m SVD\n",
    "    UtOmgM = U.T @ Omg @ M\n",
    "\n",
    "    BkF2 = np.sum(eig[1:k])\n",
    "    kernel = np.diag(1 / (eig + (frobA - BkF2) / k))\n",
    "\n",
    "    for i in range(t):\n",
    "        m = UtOmgM[:, i]\n",
    "        tau[i] = 4.0 * m.T.dot(kernel).dot(m)\n",
    "\n",
    "    return tau\n",
    "\n",
    "def ApproximateRidgeScores4(OmgAOmgAT, Omg, M, frobA, k, U=None, eig=None):\n",
    "    \"\"\"\n",
    "    Use random projected sketch to compute ridge leverage scores, better implementation to handle larger time steps\n",
    "    \"\"\"\n",
    "    _, t = np.shape(M)\n",
    "    tau = np.zeros((t))\n",
    "\n",
    "    if (U is None) or (eig is None):\n",
    "        U, eig, _ = sla.svd(OmgAOmgAT, full_matrices=False)  # a little m x m SVD\n",
    "\n",
    "    #UtOmgM = U.T @ Omg @ M\n",
    "    UtOmgM = np.linalg.multi_dot( [U.T, Omg, M] )  # selects best order of parenthesis, depending on the sizes\n",
    "\n",
    "    BkF2 = np.sum(eig[1:k])\n",
    "    kernel = np.diag(1 / (eig + (frobA - BkF2) / k))\n",
    "\n",
    "    for i in range(t):\n",
    "        m = UtOmgM[:, i]\n",
    "        tau[i] = 4.0 * m.T.dot(kernel).dot(m)\n",
    "\n",
    "    return tau, U, eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix is loaded\n",
      "Matrix is 5120 x 50000\n"
     ]
    }
   ],
   "source": [
    "method = 1\n",
    "idx_data = 1\n",
    "\n",
    "# A = np.load(\n",
    "#     '/home/angranl/Documents/dataset/nstx_data_ornl_demo_50000.npy'\n",
    "# ).astype(\"float64\")\n",
    "A = np.load(\n",
    "    '/Users/srbecker/NoSync/ASCR/nstx_data_ornl_demo_50000.npy'\n",
    ").astype(\"float64\")\n",
    "print(\"Matrix is loaded\")\n",
    "\n",
    "list_rank = [100, 200, 400, 800]\n",
    "list_t = None\n",
    "\n",
    "flg_random = True\n",
    "\n",
    "rng = default_rng(1)  # !For debugging\n",
    "xi = 0.005\n",
    "\n",
    "flg_debug = False\n",
    "\n",
    "m, n = np.shape(A)\n",
    "if flg_debug:\n",
    "    flg_random = False\n",
    "    l = 400\n",
    "    Omg = rng.standard_normal(size=(l, m))\n",
    "\n",
    "    A = Omg @ A\n",
    "    print(f\"Matrix is {l} x {n}\")\n",
    "else:\n",
    "    print(f\"Matrix is {m} x {n}\")\n",
    "\n",
    "# list_rank = [10]\n",
    "nReps = 1\n",
    "nAlgo = 1\n",
    "err = 0.0\n",
    "errors = np.zeros((nReps, nAlgo))\n",
    "\n",
    "dimReduced = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('starting rID...')\n",
    "t_start = time.time()\n",
    "\n",
    "C, P, IC = rID_streaming_ridge_leverage3(\n",
    "    A,\n",
    "    dimReduced,\n",
    "    dimReduced,\n",
    "    0.05,\n",
    "    0.1,\n",
    "    1.0,\n",
    "    400,\n",
    "    list_t=list_t,\n",
    "    rng=default_rng(),\n",
    ")\n",
    "# print(IC)\n",
    "\n",
    "_, nc = np.shape(C)\n",
    "print(f\"Number of selected columns is {nc}\")\n",
    "\n",
    "t_end = time.time() - t_start\n",
    "A_recon = C @ P\n",
    "A_err = A - A_recon\n",
    "err = sla.norm(A_err, \"fro\") / sla.norm(A, \"fro\")\n",
    "print(\n",
    "    f\"Online randomized ID (k={dimReduced}, overall), relative error:\\t{err:.4e}, Time: {t_end:.4f} sec\"\n",
    ")\n",
    "\n",
    "\n",
    "#! Randomized SVD Yu\n",
    "print('starting rSVD...')\n",
    "t_start = time.time()\n",
    "U, S, V = rSVDsp_streaming(A.T, b=dimReduced, k=dimReduced, rng=rng)\n",
    "V = S.reshape((-1, 1)) * V\n",
    "t_end3 = time.time() - t_start\n",
    "nrmA = sla.norm(A,'fro')\n",
    "norm_f = fastFrobeniusNorm(U, V, A.T, nrmA) / nrmA\n",
    "print(\n",
    "    \"rSVDsp_unblock_streaming, relative error:\\t\\t\\t{0:.2e}, Time: {1:.4f} sec\".format(\n",
    "        norm_f, t_end3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Matrix is loaded\n",
    "Matrix is 5120 x 50000\n",
    "starting rID...\n",
    "Number of selected columns is 100\n",
    "Online randomized ID (k=100, overall), relative error:\t1.3826e-01, Time: 151.6322 sec\n",
    "starting rSVD...\n",
    "rSVDsp_unblock_streaming, relative error:\t\t\t1.21e-01, Time: 673.8001 sec\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AA = A[:,:10000] # A is 5120 x 50000.  With just 10,000 columns, and dim=100 for Omega, rSVD now takes 3 seconds\n",
    "# AA = A[:,:20000] # now 6 seconds\n",
    "# AA = A[:,:35000] # now 10 seconds\n",
    "AA = A  # now 14 seconds instead of 673 seconds!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AA.flags['F_CONTIGUOUS']  # why???\n",
    "\n",
    "AAt.flags['F_CONTIGUOUS'] # False\n",
    "AA.T.flags['F_CONTIGUOUS'] # False\n",
    "\n",
    "# \"Calling ascontiguousarray makes a C-contiguous copy\" ... or b = np.copy(a.transpose(0,2,1), order='C') \n",
    "#  C contiguous means row-major order;  F (Fortran) contiguous means column-major order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from rSVDsp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting rSVD...\n",
      "Took 0.00004s to transpose and copy data\n",
      "rSVDsp_unblock_streaming, relative error:\t\t\t1.21e-01, Time: 14.8845 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 14.1003 s\n",
      "File: /Users/srbecker/Repos/ASCR_DataReduction/src/rSVDsp.py\n",
      "Function: onepass_update at line 103\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   103                                           def onepass_update(A,Omega,blockSize=1):\n",
      "   104                                               \"\"\" Computes G = A@Omega and H = A.T@G in one-pass,\n",
      "   105                                               loading in at most 'blockSize' rows of A at a time \"\"\"\n",
      "   106         1         23.0     23.0      0.0      m, n = np.shape(A)\n",
      "   107         1          6.0      6.0      0.0      k = np.shape(Omega)[1]\n",
      "   108                                           \n",
      "   109         1          5.0      5.0      0.0      G = np.zeros((0,k))\n",
      "   110         1        219.0    219.0      0.0      H = np.zeros((n,k))\n",
      "   111                                               #print(f\"Row-major order (C order) is: {A.flags['C_CONTIGUOUS']}\")\n",
      "   112                                               \n",
      "   113         1          4.0      4.0      0.0      if blockSize == 1:\n",
      "   114         1         24.0     24.0      0.0          G = np.zeros((m,k))   # preallocate for speed\n",
      "   115         1        504.0    504.0      0.0          aTg = np.zeros((n,k)) # we'll reuse the same memory for speed\n",
      "   116     50001      42757.0      0.9      0.3          for row in range(m):\n",
      "   117     50000     124234.0      2.5      0.9              a = A[row, :].reshape((1,n))\n",
      "   118     50000    3400045.0     68.0     24.1              g = a @ Omega\n",
      "   119     50000     192271.0      3.8      1.4              G[row,:] = g # faster than G = np.vstack((G, g))\n",
      "   120                                           \n",
      "   121                                                       # H = H + a.T @ g # Slow (23.1 sec)\n",
      "   122                                           \n",
      "   123                                                       # H += np.outer(a,g)  # Medium (16.3 sec)\n",
      "   124                                           \n",
      "   125                                                       # np.outer(a,g, out = aTg) \n",
      "   126                                                       # H += aTg  # Medium fast (11.6 sec)\n",
      "   127                                                       \n",
      "   128                                                       # H = scipy.linalg.blas.dger(1.0,a.flatten(), g.flatten(), a=H, overwrite_a = 0) # Fast (7.3 sec)\n",
      "   129     50000   10340206.0    206.8     73.3              H = scipy.linalg.blas.dger(1.0,a.flatten(), g.flatten(), a=H, overwrite_a = 1) # Fastest (3.2 sec)\n",
      "   130                                               else:\n",
      "   131                                                   # New code\n",
      "   132                                                   nBlocks = int( m / blockSize )\n",
      "   133                                                   for j in range(nBlocks):\n",
      "   134                                                       a = A[j*blockSize:(j+1)*blockSize, :] #.reshape((1,n))\n",
      "   135                                                       g = a @ Omega\n",
      "   136                                                       G = np.vstack((G, g))\n",
      "   137                                                       H = H + a.T@g\n",
      "   138                                                   if nBlocks*blockSize < m:\n",
      "   139                                                       # add the stragglers\n",
      "   140                                                       a = A[nBlocks*blockSize:, :] #.reshape((1,n))\n",
      "   141                                                       g = a @ Omega\n",
      "   142                                                       G = np.vstack((G, g))\n",
      "   143                                                       H = H + a.T@g\n",
      "   144                                               \n",
      "   145         1          1.0      1.0      0.0      return G, H"
     ]
    }
   ],
   "source": [
    "#! Randomized SVD Yu\n",
    "print('starting rSVD...')\n",
    "t_start = time.time()\n",
    "# AAt = np.ascontiguousarray( AA.T.copy() ) # put in C order. Doesn't help, it already is!!\n",
    "t_end0 = time.time() - t_start\n",
    "print(f'Took {t_end0:.5f}s to transpose and copy data')\n",
    "# AAt = np.copy( AA.T, order='F') # force F order\n",
    "AAt = AA.T  # a view\n",
    "t_start = time.time()\n",
    "# %prun U, S, V = rSVDsp_streaming(AAt, b=dimReduced, k=dimReduced, rng=rng)\n",
    "# %lprun -f rSVDsp_streaming U, S, V = rSVDsp_streaming(AAt, b=dimReduced, k=dimReduced, rng=rng, blocksize_A = 1)\n",
    "# %lprun -f onepass_update U, S, V = rSVDsp_streaming(AAt, b=dimReduced, k=dimReduced, rng=rng, blocksize_A = 1)\n",
    "U, S, V = rSVDsp_streaming(AAt, b=dimReduced, k=dimReduced, rng=rng, blocksize_A = 1)\n",
    "t_end3 = time.time() - t_start\n",
    "V = S.reshape((-1, 1)) * V\n",
    "t_end3 = time.time() - t_start\n",
    "nrmA = sla.norm(A,'fro')\n",
    "norm_f = fastFrobeniusNorm(U, V, AA.T, nrmA) / nrmA\n",
    "print(    \"rSVDsp_unblock_streaming, relative error:\\t\\t\\t{0:.2e}, Time: {1:.4f} sec\".format( norm_f, t_end3    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blas_mkl_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/Users/srbecker/opt/anaconda3/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/Users/srbecker/opt/anaconda3/include']\n",
      "blas_opt_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/Users/srbecker/opt/anaconda3/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/Users/srbecker/opt/anaconda3/include']\n",
      "lapack_mkl_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/Users/srbecker/opt/anaconda3/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/Users/srbecker/opt/anaconda3/include']\n",
      "lapack_opt_info:\n",
      "    libraries = ['mkl_rt', 'pthread']\n",
      "    library_dirs = ['/Users/srbecker/opt/anaconda3/lib']\n",
      "    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "    include_dirs = ['/Users/srbecker/opt/anaconda3/include']\n",
      "Supported SIMD extensions in this NumPy install:\n",
      "    baseline = SSE,SSE2,SSE3\n",
      "    found = SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,FMA3,AVX2\n",
      "    not found = AVX512F,AVX512CD,AVX512_KNL,AVX512_SKX,AVX512_CLX,AVX512_CNL,AVX512_ICL\n"
     ]
    }
   ],
   "source": [
    "np.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now profile the rID code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AA = A[:,:5000] # A is 5120 x 50000.  With just 10,000 columns, and dim=100 for Omega, rSVD now takes 3 seconds\n",
    "# AA = A[:,:20000] # now 6 seconds\n",
    "# AA = A[:,:35000] # now 10 seconds\n",
    "# AA = A  # now 14 seconds instead of 673 seconds!!!\n",
    "AA.flags['F_CONTIGUOUS'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags:\n",
      "False\n",
      "False\n",
      "Online randomized ID (k=100, overall), relative error:\t1.2982e-01, Time: 0.0000 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 18.2882 s\n",
      "File: /var/folders/m6/qx5hnd757jx4frp_fw3cdwkw0000gn/T/ipykernel_30416/802246270.py\n",
      "Function: rID_streaming_ridge_leverage3 at line 146\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   146                                           def rID_streaming_ridge_leverage3(\n",
      "   147                                               A, k, t, epsilon, delta, c, os, list_t=None, rng=default_rng()\n",
      "   148                                           ):\n",
      "   149                                               \"\"\"\n",
      "   150                                               from http://arxiv.org/abs/1511.07263\n",
      "   151                                               A should be n by d\n",
      "   152                                               k is the rank of the projection with theoretical guarantees.\n",
      "   153                                               t is the stored column size\n",
      "   154                                               epsilon: accuracy parameter\n",
      "   155                                               delta: (1-delta) is the success probability\n",
      "   156                                               c: oversampling parameter\n",
      "   157                                               os: oversampling number for random projection\n",
      "   158                                               choose epsilon and delta to be less than one.\n",
      "   159                                               \"\"\"\n",
      "   160         1         11.0     11.0      0.0      n, d = np.shape(A)\n",
      "   161         1          1.0      1.0      0.0      ll = k + os\n",
      "   162         1      37735.0  37735.0      0.2      Omg = rng.standard_normal(size=(ll, n))\n",
      "   163                                           \n",
      "   164         1          2.0      2.0      0.0      count = 0\n",
      "   165         1          1.0      1.0      0.0      nBlock = 0\n",
      "   166         1       2260.0   2260.0      0.0      C = np.zeros((n, t))  # Stores actual column subset\n",
      "   167         1       8482.0   8482.0      0.0      D = np.zeros((n, t))  # Stores a queue of new columns\n",
      "   168         1        111.0    111.0      0.0      IC = -1 * np.ones((t)).astype(int)\n",
      "   169         1          6.0      6.0      0.0      ID = np.zeros((t)).astype(int)\n",
      "   170         1          1.0      1.0      0.0      frobA = 0\n",
      "   171                                           \n",
      "   172         1      16688.0  16688.0      0.1      Q = np.zeros((t, d))\n",
      "   173         1          3.0      3.0      0.0      C_old = C\n",
      "   174         1      26531.0  26531.0      0.1      OmgA = np.zeros((ll, d))\n",
      "   175         1       1878.0   1878.0      0.0      OmgAOmgAt = np.zeros((ll, ll))\n",
      "   176         1        172.0    172.0      0.0      OmgAOmgAt2 = OmgAOmgAt.copy()\n",
      "   177         1        112.0    112.0      0.0      print('flags:')\n",
      "   178         1         16.0     16.0      0.0      print(OmgAOmgAt.flags['F_CONTIGUOUS'])\n",
      "   179         1         11.0     11.0      0.0      print(OmgAOmgAt2.flags['F_CONTIGUOUS'])\n",
      "   180                                           \n",
      "   181         1         27.0     27.0      0.0      tau_old = np.ones((t))  # Initialize sampling probabilities\n",
      "   182         1          3.0      3.0      0.0      tau = np.zeros((t))\n",
      "   183         1          2.0      2.0      0.0      probabilities = np.zeros((t))\n",
      "   184                                           \n",
      "   185      5001       7167.0      1.4      0.0      for i in range(d):\n",
      "   186      5000      13463.0      2.7      0.1          a = A[:, i].T\n",
      "   187      5000    5007143.0   1001.4     27.4          OmgA[:, i] = Omg @ A[:, i]\n",
      "   188      5000    1101803.0    220.4      6.0          OmgAOmgAt = OmgAOmgAt + OmgA[:, i] @ OmgA[:, i].T\n",
      "   189      5000    2432959.0    486.6     13.3          OmgAOmgAt2 += np.outer(OmgA[:, i], OmgA[:, i] )\n",
      "   190      5000    2225061.0    445.0     12.2          OmgAOmgAt2 = OmgAOmgAt2 + np.outer(OmgA[:, i], OmgA[:, i] )\n",
      "   191      5000    2159131.0    431.8     11.8          OmgAOmgAt2 = OmgAOmgAt2 + np.outer(OmgA[:, i].flatten(), OmgA[:, i].flatten() )\n",
      "   192                                                   # OmgAOmgAt = scipy.linalg.blas.dsyr(1.0,OmgA[:, i].flatten(),  a=OmgAOmgAt, overwrite_a = 1) # not good because only overwrites upper triangular portion, so needs postprocessing\n",
      "   193                                                   #OmgAOmgAt = scipy.linalg.blas.dger(1.0,OmgA[:, i].flatten(),OmgA[:, i].flatten(), overwrite_x = 0, overwrite_y = 0, a=OmgAOmgAt, overwrite_a = 1) # not good because only overwrites upper triangular portion, so needs postprocessing\n",
      "   194      5000      10629.0      2.1      0.1          if count < t:\n",
      "   195      4951     234109.0     47.3      1.3              D[:, count] = A[:, i]\n",
      "   196      4951      12443.0      2.5      0.1              ID[count] = i\n",
      "   197      4951     242680.0     49.0      1.3              frobA = frobA + sla.norm(a) ** 2\n",
      "   198      4951       8287.0      1.7      0.0              count = count + 1\n",
      "   199                                                   else:\n",
      "   200                                                       # tau = np.minimum(tau_old, ApproximateRidgeScores2(OmgA[:,:i], Omg, C, frobA, k))\n",
      "   201                                                       # tau_D = ApproximateRidgeScores2(OmgA[:,:i], Omg, D, frobA, k)\n",
      "   202        49    3856873.0  78711.7     21.1              tau, U, eig = ApproximateRidgeScores4(OmgAOmgAt, Omg, C, frobA, k) # returns eigenvalues/vectors\n",
      "   203        49        374.0      7.6      0.0              tau = np.minimum( tau_old, tau )\n",
      "   204        49     627440.0  12804.9      3.4              tau_D = ApproximateRidgeScores4(OmgAOmgAt, Omg, D, frobA, k, U=U, eig=eig)[0]\n",
      "   205      4949       4534.0      0.9      0.0              for j in range(t):\n",
      "   206      4900       6138.0      1.3      0.0                  if IC[j] != -1:\n",
      "   207      4800       6552.0      1.4      0.0                      prob_rej = 1.0 - tau[j] / tau_old[j]\n",
      "   208      4800       8972.0      1.9      0.0                      roll = rng.random()\n",
      "   209      4800       5047.0      1.1      0.0                      if roll < prob_rej:\n",
      "   210       675      15495.0     23.0      0.1                          C[:, j] = 0\n",
      "   211       675        974.0      1.4      0.0                          tau_old[j] = 1.0\n",
      "   212       675        917.0      1.4      0.0                          IC[j] = -1\n",
      "   213                                                               else:\n",
      "   214      4125       4828.0      1.2      0.0                          tau_old[j] = tau[j]\n",
      "   215                                           \n",
      "   216        49       2094.0     42.7      0.0              num_sample = np.sum(IC < 0)\n",
      "   217                                                       # print(f'Sum tauD: {np.sum(tau)}')\n",
      "   218                                                       # print(f'Sum tauD: {np.sum(tau_D)}')\n",
      "   219                                                       # print(f'Sum: {np.sum(probabilities)}')\n",
      "   220        98       9630.0     98.3      0.1              idx_sample = np.random.choice(\n",
      "   221        49       1108.0     22.6      0.0                  ID, num_sample, p=tau_D / np.sum(tau_D), replace=False\n",
      "   222                                                       )\n",
      "   223                                                       # print(num_sample)\n",
      "   224                                                       # print(IC)\n",
      "   225                                                       # print(ID)\n",
      "   226                                                       # print(idx_sample)\n",
      "   227        49         72.0      1.5      0.0              count_sample = 0\n",
      "   228      4949       4509.0      0.9      0.0              for j in range(t):\n",
      "   229      4900       6111.0      1.2      0.0                  if IC[j] < 0:\n",
      "   230       775       1029.0      1.3      0.0                      IC[j] = idx_sample[count_sample]\n",
      "   231       775       6793.0      8.8      0.0                      idx_D = np.where(ID == IC[j])[0][0]\n",
      "   232                                                               # print(idx_D)\n",
      "   233       775       1295.0      1.7      0.0                      tau_old[j] = tau_D[idx_D]\n",
      "   234       775      36659.0     47.3      0.2                      C[:, j] = D[:, idx_D]\n",
      "   235       775       1017.0      1.3      0.0                      count_sample = count_sample + 1\n",
      "   236                                           \n",
      "   237                                                           # if IC[j] == -1:\n",
      "   238                                                           #     for l in range(t):\n",
      "   239                                                           #         prob = tau_D[l]*c*(k*np.log(k)+k*np.log(1./delta)/epsilon)/t\n",
      "   240                                                           #         # prob = tau_D[l]/32.\n",
      "   241                                                           #         roll = rng.random()\n",
      "   242                                                           #         if roll < prob:\n",
      "   243                                                           #             C[:,j] = D[:, l]\n",
      "   244                                                           #             tau_old[j] = tau_D[l]\n",
      "   245                                                           #             IC[j] = ID[l]\n",
      "   246                                           \n",
      "   247                                                       # Q[:,(nBlock)*t:(nBlock+1)*t] = sla.lstsq(Omg @ C, OmgA[:, (nBlock)*t:(nBlock+1)*t])[0]\n",
      "   248                                                       # if nBlock == 0:\n",
      "   249                                                       #     C_old = C\n",
      "   250                                                       # else:\n",
      "   251                                                       #     P = sla.lstsq(C, C_old)[0]\n",
      "   252                                                       #     C_old = C\n",
      "   253                                                       #     Q[:,:(nBlock)*t] = P @ Q[:,:(nBlock)*t]\n",
      "   254        49         42.0      0.9      0.0              count = 0\n",
      "   255                                                       # nBlock = nBlock + 1\n",
      "   256                                           \n",
      "   257                                               # if nBlock * t < d:\n",
      "   258                                               #     Q[:, (nBlock)*t:] = sla.lstsq(Omg @ C, OmgA[:, (nBlock)*t:])[0]\n",
      "   259         1      40898.0  40898.0      0.2      C = np.unique(C, axis=1)\n",
      "   260                                               # print(C)\n",
      "   261                                           \n",
      "   262         1      89819.0  89819.0      0.5      Q = sla.lstsq(Omg @ C, OmgA)[0]\n",
      "   263                                           \n",
      "   264                                           \n",
      "   265         1         58.0     58.0      0.0      IC = np.unique(IC)\n",
      "   266                                           \n",
      "   267         1          1.0      1.0      0.0      return C, Q, IC"
     ]
    }
   ],
   "source": [
    "# %lprun -f ApproximateRidgeScores4  C, P, IC = rID_streaming_ridge_leverage3(AA, dimReduced, dimReduced, 0.05, 0.1, 1.0, 400, list_t=list_t, rng=default_rng(), )\n",
    "\n",
    "%lprun -f rID_streaming_ridge_leverage3  C, P, IC = rID_streaming_ridge_leverage3(AA, dimReduced, dimReduced, 0.05, 0.1, 1.0, 400, list_t=list_t, rng=default_rng(), )\n",
    "\n",
    "A_recon = C @ P\n",
    "A_err = AA - A_recon\n",
    "err = sla.norm(A_err, \"fro\") / sla.norm(AA, \"fro\")\n",
    "t_end=0.\n",
    "print(f\"Online randomized ID (k={dimReduced}, overall), relative error:\\t{err:.4e}, Time: {t_end:.4f} sec\")\n",
    "# relative error:\t1.0735e-01, or 1.2738e-01, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
